{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# How to prepare the audio? (manually)\n",
        "- select any long single audio file.\n",
        "- extract the audio and the substitles.\n",
        "- then in audacity start a new project\n",
        "  - import the audio file\n",
        "  - then in Tracks>>Add New>>Label Tracks\n",
        "  - then make sure each 10-20 secs audio has the label (this is the longest task)\n",
        "  - as for export options:\n",
        "    - select the folder (ideally an empty one) where you want your WAV files to be placed\n",
        "    - for audio options choose Mono\n",
        "    - for sample rate, choose \"Other\" and type 24000 into the dialog that comes up\n",
        "    - for export range, choose Multiple Files\n",
        "    - for the \"Split files based on\" section, choose Labels\n",
        "    - in the \"Name files\" section, choose \"Numbering after File name prefix\" and choose a prefix that you'll also use in the TTS training Notebook (such as \"B1\" or similar)\n",
        "    - click on Export"
      ],
      "metadata": {
        "id": "BiCSXz94zjBJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to prepare the audio? (Automactically)\n",
        "follow this [notebook](https://colab.research.google.com/drive/1ZK-2lAV2DokrN92sYPJRl47XyuuluCJe?usp=sharing). but not reliable resource as it use whisper to transcribe and label."
      ],
      "metadata": {
        "id": "-RLQ0KYL2TRf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prerequisities for this ipynb:\n",
        "- audio should be 12-20 secs long\n",
        "- and the folder should contain label.txt file init.\n",
        "- label.txt file must be audacity compatible\n",
        "- convert the folder in zip file and then upload here to make them ready for training.\n",
        "- *ZIP file example:*\n",
        "  - *B1-00001.wav*\n",
        "  - *B1-00002.wav*\n",
        "  - *B1-00003.wav*\n",
        "  - *B1-00004.wav*\n",
        "  - *labels.txt*\n",
        "\n",
        "- name your files:\n",
        "    - name your files, so they begin with the **same prefix** and always **have 5 digits** after it (such as B1-, e.g. *B1-00001.wav*)\n",
        "- results structure:\n",
        "  - *ZIP file example:*\n",
        "    - *metadata.csv*\n",
        "    - *metadata_phonetical.csv*\n",
        "    - *training.csv*\n",
        "    - *validation.csv*\n",
        "    - *wavs/B1-00001.wav*\n",
        "    - *wavs/B1-00002.wav*\n",
        "    - *wavs/B1-00003.wav*\n",
        "    - *wavs/B1-00004.wav*"
      ],
      "metadata": {
        "id": "W7DEsCFGyYov"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hPz96-1-ttll"
      },
      "outputs": [],
      "source": [
        "#################\n",
        "# Settings Form #\n",
        "#################\n",
        "\n",
        "# @title 1. Settings & Data Sources\n",
        "# @markdown ***Data source to be used:***\n",
        "# @markdown <small>(choose a data source options and then run this cell)</small>\n",
        "data_source = \"Google Drive (Google Colab only)\" # @param [\"Google Drive (Google Colab only)\", \"External Files (Dropbox etc.)\"]\n",
        "\n",
        "# @markdown ***Path of a ZIP file containing WAV files:***\n",
        "# @markdown <br><small>An archive with all WAV files to be used for training.</small>\n",
        "# @markdown <br><small>See [Section 0](#scrollTo=6DEC0-d48M-G) to verify that your ZIP file is in the correct form.</small>\n",
        "# @markdown <br><small>If you're using Google Colab, this is the relative path from your Drive root (e.g. *tts/wavs.zip*)</small>\n",
        "# @markdown <br><small>If you're using External Files, use a full URL (e.g. *https://www.example.com/wavs.zip*)</small>\n",
        "wav_files_path = \"tts/wavs.zip\" # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ***WAV files prefix:***\n",
        "# @markdown <br><small>Prefix for each of the WAV files, as described in [Section 0](#scrollTo=6DEC0-d48M-G).</small>\n",
        "wavs_prefix = 'B1-' # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ***WAV files in ZIP archive are already prepared:***\n",
        "# @markdown <br><small>If you're resuming training or have previously prepared your WAV files, so they conform to the structure generated by this Notebook (see [Section 0](#scrollTo=6DEC0-d48M-G)), tick this checkbox. In such case, this Notebook will not try to convert your WAV files, nor will trim leading and trailing silences from them.</small>\n",
        "wav_files_prepared_for_training = False # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown ***Silence trimming treshold:***\n",
        "# @markdown <br><small>This value is used as the \"*-af silenceremove*\" ffmpeg parameter.</small>\n",
        "# @markdown <br><small>I found the default (-60dB) to be good enough to trim silences from well-recorded, denoised WAV files.</small>\n",
        "# @markdown <br><small>If this trims too much of the audio, try -96dB for a more lenient trim.</small>\n",
        "db_trim_value = \"-60dB\" # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ***1st stage model ZIP archive (restoration):***\n",
        "# @markdown <br><small>If you're resuming training and have your 1st stage model (and potentially its config file) stored in a ZIP files, provide its path here.</small>\n",
        "# @markdown <br><small>If you're using Google Colab, this is the relative path from your Drive root (e.g. *tts/model_training_checkpoint.zip*)</small>\n",
        "# @markdown <br><small>If you're using External Files, use a full URL (e.g. *https://www.example.com/model_training_checkpoint.zip*)</small>\n",
        "model_1st_stage_backup_zip_file_path = \"tts/model_backup_stage_1.zip\" # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ***2nd stage model ZIP archive (restoration):***\n",
        "# @markdown <br><small>If you're resuming training and have your 2nd stage model (and potentially its config file) stored in a ZIP files, provide its path here.</small>\n",
        "# @markdown <br><small>If you're using Google Colab, this is the relative path from your Drive root (e.g. *tts/model_training_checkpoint_stage_2.zip*)</small>\n",
        "# @markdown <br><small>If you're using External Files, use a full URL (e.g. *https://www.example.com/model_training_checkpoint_stage_2.zip*)</small>\n",
        "model_2nd_stage_backup_zip_file_path = \"tts/model_backup_stage_2.zip\" # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ***Phonemization language:***\n",
        "# @markdown <br><small>This language will be used to convert your text into phonemes.</small>\n",
        "# @markdown <br><small>This value must be one of the languages compatible with the phonemizer: https://pypi.org/project/phonemizer/</small>\n",
        "# @markdown <br><small>For example, if you're using the default espeak phonemization: https://github.com/espeak-ng/espeak-ng/blob/master/docs/languages.md</small>\n",
        "phonemization_language = 'en-us' # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ***Training VS validation data percentage:***\n",
        "# @markdown <br><small>This value says how much % of the total data will be used for training.</small>\n",
        "# @markdown <br><small>Default value: 90 (i.e. 90% training data, 10% validation data)</small>\n",
        "training_data_percentage = 90 # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown ***Labels text replacements:***\n",
        "# @markdown <br><small>In case some words in your labels.txt file are pronounced differently than they appear, set your replacement rules here.</small>\n",
        "# @markdown <br><small>This text is in a JSON form and needs to be updated in the same form in order for this cell to keep working.</small>\n",
        "# @markdown <br><small>The example default are some replacements from a fantasy book, so you can see the syntax of the JSON value.</small>\n",
        "text_replacements = { \"Bannick\":\"ban-nick\", \"Banshee\": \"ban-shee\", \"Cait Sidhe\": \"kay-th shee\", \"Coblynau\": \"cob-lee-now\", \"Daoine\": \"doon-ya\", \"Djinn\": \"jin\", \"Glastig\": \"glass-tig\", \"Gwragen\": \"guh-war-a-gen\", \"Kelpie\": \"kel-pee\", \"Kitsune\": \"kit-soon\", \"Lamia\": \"lay-me-a\", \"Manticore\": \"man-tee-core\", \"Nixie\": \"nix-ee\", \"Peri\": \"pear-ee\", \"Piskie\": \"piss-key\", \"Pixie\": \"pix-ee\", \"Puca\": \"puh-ca\", \"Roane\": \"ro-an\", \"Selkie\": \"sell-key\", \"Sidhe\": \"shee\", \"Silene\": \"sigh-lean\", \"The Luidaeg\": \"the lou-sha-k\", \"Tuatha\": \"tootha\", \"de Dannan\": \"day danan\", \"Tybalt\": \"tiebolt\", \"Tylwyth\": \"till-with\", \"Teg\": \"teeg\", \"Undine\": \"un-deen\", \"Will o' Wisp\": \"will-oh wisp\", \"de Dannan\": \"day danan\" } # @param {type:\"raw\"}\n",
        "\n",
        "\n",
        "##################\n",
        "# Execution Code #\n",
        "##################\n",
        "if data_source == \"Google Drive (Google Colab only)\":\n",
        "  from google.colab import drive\n",
        "  drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DA-R81AFNeY"
      },
      "source": [
        "# 2. Required programs and libraries\n",
        "\n",
        "This section will install everything you'll need later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Al3fazc-EdOB"
      },
      "outputs": [],
      "source": [
        "# install system packages (Debian, Ubuntu)\n",
        "!sudo apt update && sudo apt -y install curl ffmpeg sox libtool musl-dev gcc-multilib g++-multilib espeak espeak-ng sox zip unzip\n",
        "\n",
        "# install Python dependencies\n",
        "!pip install pyloudnorm soundfile nltk phonemizer wget"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t843fpgS6jGO"
      },
      "source": [
        "# 3. Labels and WAV Files Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBYZXt0d9NnL"
      },
      "outputs": [],
      "source": [
        "if wav_files_path == \"\":\n",
        "  raise Exception(\"The wav_files_path setting is empty. Please set this option in section 1, then run the cell in section 1 and re-run this cell again.\")\n",
        "\n",
        "# copy WAV files from Google Drive, if we are using it\n",
        "if data_source == \"Google Drive (Google Colab only)\":\n",
        "  !cp /gdrive/MyDrive/$wav_files_path ./wavs.zip\n",
        "else:\n",
        "# download WAV files from a predefined location\n",
        "  import wget\n",
        "  wget.download( wav_files_path, 'wavs.zip' )\n",
        "\n",
        "# extract WAV files from the ZIP file into a local folder\n",
        "!rm -rf wavs\n",
        "!mkdir wavs\n",
        "!unzip wavs.zip -d wavs\n",
        "!rm -f wavs.zip\n",
        "\n",
        "# prepare WAV files from original ones to a safely-renamed ones\n",
        "# and phonemize the labels.txt file, so it can be used with the StyleTTS2 system\n",
        "import os\n",
        "import nltk\n",
        "import phonemizer\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from shutil import copyfile, rmtree\n",
        "from pathlib import Path\n",
        "\n",
        "if wav_files_prepared_for_training == False:\n",
        "  nltk.download('punkt')\n",
        "  global_phonemizer = phonemizer.backend.EspeakBackend( language=phonemization_language, preserve_punctuation=True, with_stress=True )\n",
        "\n",
        "def text_to_phonemes(text):\n",
        "  text = text.strip()\n",
        "  #print(\"Text before phonemization: \", text)\n",
        "  ps = global_phonemizer.phonemize([text])\n",
        "  #print(\"Text after phonemization: \", ps)\n",
        "  ps = word_tokenize(ps[0])\n",
        "  ps = ' '.join(ps)\n",
        "  #print(\"Final text after tokenization: \", ps)\n",
        "  return ps\n",
        "\n",
        "wavs_counter = 1\n",
        "wavs_export_path = './wavs'\n",
        "wavs_processed_path = './wavs_processed'\n",
        "wavs_final_path = './wavs_final'\n",
        "wavs_filtered_path = './wavs_filtered'\n",
        "input_filename = './wavs/labels.txt'\n",
        "output_filename_clean = './wavs_final/metadata.csv'\n",
        "output_filename_phonetical = './wavs_final/metadata_phonetical.csv'\n",
        "\n",
        "if wav_files_prepared_for_training == False:\n",
        "  # change Windows CR+LF line endings to Linux LF line endings\n",
        "  WINDOWS_LINE_ENDING = b'\\r\\n'\n",
        "  UNIX_LINE_ENDING = b'\\n'\n",
        "\n",
        "  with open( input_filename, 'rb' ) as open_file:\n",
        "    content = open_file.read()\n",
        "\n",
        "  # Windows ➡ Unix\n",
        "  content = content.replace( WINDOWS_LINE_ENDING, UNIX_LINE_ENDING )\n",
        "\n",
        "  # Unix ➡ Windows\n",
        "  # content = content.replace( UNIX_LINE_ENDING, WINDOWS_LINE_ENDING )\n",
        "\n",
        "  with open( input_filename, 'wb') as open_file:\n",
        "      open_file.write(content)\n",
        "\n",
        "\n",
        "# delete and recreate wavs_final_path when rerunning\n",
        "if wav_files_prepared_for_training == False:\n",
        "  if os.path.exists(wavs_final_path):\n",
        "    rmtree(wavs_final_path)\n",
        "  os.mkdir(wavs_final_path)\n",
        "\n",
        "  # delete and recreate wavs_processed_path when rerunning\n",
        "  if os.path.exists(wavs_processed_path):\n",
        "    rmtree(wavs_processed_path)\n",
        "  os.mkdir(wavs_processed_path)\n",
        "\n",
        "  fp_clean = open(output_filename_clean, 'w')\n",
        "  fp_phonetical = open(output_filename_phonetical, 'w')\n",
        "\n",
        "  df = pd.read_csv(input_filename, sep='\\t', encoding='utf-8', usecols=[0, 1, 2], names=['Start', 'End', 'Description'], quoting=3)\n",
        "\n",
        "  for sentence in df['Description'].to_list():\n",
        "    if not pd.isnull(sentence):\n",
        "      # replace special words\n",
        "      for original_text, replacement_text in text_replacements.items():\n",
        "        sentence = sentence.replace( original_text, replacement_text )\n",
        "\n",
        "      # adjust file name\n",
        "      real_counter = str( wavs_counter )\n",
        "      if wavs_counter < 10:\n",
        "        real_counter = '0000' + real_counter\n",
        "      elif wavs_counter < 100:\n",
        "        real_counter = '000' + real_counter\n",
        "      elif wavs_counter < 1000:\n",
        "        real_counter = '00' + real_counter\n",
        "      elif wavs_counter < 10000:\n",
        "        real_counter = '0' + real_counter\n",
        "\n",
        "      wav_path_orig = wavs_prefix + real_counter + \".wav\"\n",
        "      wav_path = wav_path_orig.replace(\" \", \"_\").replace(\"M\", \"m\")\n",
        "      wav_filename = wav_path.replace(\".wav\", \"\")\n",
        "      copyfile(wavs_export_path + '/' + wav_path_orig, wavs_processed_path + '/' + wav_path)\n",
        "      print(wavs_prefix + real_counter + '.wav (' + ( wavs_processed_path + '/' + wav_path ) + '): ' + sentence)\n",
        "\n",
        "      # write the sentence into the original LJSpeech metadata form file\n",
        "      fp_clean.write(f\"{wav_filename}|{sentence}|{sentence}\\n\")\n",
        "\n",
        "      # transliterate using espeak's phonemizer to conform with StyleTTS2's expected input\n",
        "      phonemized = text_to_phonemes( sentence )\n",
        "      fp_phonetical.write(f\"{wav_filename}.wav|{phonemized}|0\\n\")\n",
        "      wavs_counter = wavs_counter + 1\n",
        "  fp_clean.close()\n",
        "  fp_phonetical.close()\n",
        "else:\n",
        "  # we've uploaded prepared WAV files, just rename the folder\n",
        "  !mv ./wavs ./wavs_final\n",
        "\n",
        "\n",
        "# process WAV files, trimming leading and ending silences,\n",
        "# converting their sample rate to 24k and changing them to mono\n",
        "if wav_files_prepared_for_training == False:\n",
        "  paths = Path( wavs_processed_path ).glob(\"**/*.wav\")\n",
        "  processing_index = 0\n",
        "  paths_length = len( os.listdir( wavs_processed_path ) )\n",
        "\n",
        "  temp1 = wavs_processed_path + \"/temp1.wav\"\n",
        "  temp2 = wavs_processed_path + \"/temp2.wav\"\n",
        "  temp3 = wavs_processed_path + \"/temp3.wav\"\n",
        "\n",
        "  for filepath in paths:\n",
        "    file = str(filepath)\n",
        "    if file.endswith(\".wav\"):\n",
        "      processing_index = processing_index + 1;\n",
        "      print( str( processing_index ) + \" / \" + str( paths_length ) + \": processing \" + file + \", output into \" + file.replace( wavs_processed_path.replace( \"./\", \"\" ), wavs_final_path ) )\n",
        "      os.popen(\"ffmpeg -i \" + file + \" -af silenceremove=1:0:\" + db_trim_value +\" \" + temp1).read()\n",
        "      os.popen(\"ffmpeg -i \" + temp1 + \" -af areverse \" + temp2).read()\n",
        "      #os.popen(\"ffmpeg -i \" + temp2 + \" -af silenceremove=1:0:-96dB \" + temp3).read()\n",
        "      os.popen(\"ffmpeg -i \" + temp2 + \" -af silenceremove=1:0:\" + db_trim_value + \" \" + temp3).read()\n",
        "      os.popen(\"ffmpeg -y -i \" + temp3 + \" -map_metadata -1 -af areverse -ar 24000 -ac 1 \" + file.replace( wavs_processed_path.replace( \"./\", \"\" ), wavs_final_path ) ).read()\n",
        "      os.remove(temp1)\n",
        "      os.remove(temp2)\n",
        "      os.remove(temp3)\n",
        "\n",
        "\n",
        "  # randomize metadata file, so the phrases from labels.txt are fed to this TTS system in random sequence\n",
        "  !shuf ./wavs_final/metadata_phonetical.csv > ./wavs_final/shuffled.csv\n",
        "\n",
        "\n",
        "  # prepare a script that would split the resulting phonetical transcription\n",
        "  # into training and validation file by a ratio of 90:10 by default (10% validation data, 90% training data)\n",
        "  # (this can be changed by changing the training_data_percentage variable on top of this Notebook)\n",
        "  with open('splitter.sh', 'w') as file:\n",
        "    file.write('''# Specify the names for the training and validation files\n",
        "training_file=\"training.csv\"\n",
        "validation_file=\"validation.csv\"\n",
        "\n",
        "# Calculate the line count for the split\n",
        "total_lines=$(wc -l ./wavs_final/shuffled.csv | cut -d\" \" -f1)\n",
        "training_lines=$((total_lines * {training_data_percentage} / 100))\n",
        "\n",
        "# Use the split command with the specified names for output files\n",
        "cd ./wavs_final && split -l $training_lines shuffled.csv \"$training_file\"_\n",
        "\n",
        "# Rename the generated files to the desired names\n",
        "mv ./\"$training_file\"_aa ./\"$training_file\"\n",
        "mv ./\"$training_file\"_ab ./\"$validation_file\"\n",
        "rm -f ./shuffled.csv'''.format(training_data_percentage = training_data_percentage));\n",
        "\n",
        "  !sudo chmod +x ./splitter.sh\n",
        "  !./splitter.sh\n",
        "\n",
        "\n",
        "  # cleanup temporary folders and move WAV files into a TTS structure\n",
        "  !rm -rf ./wavs\n",
        "  !rm -rf ./wavs_processed\n",
        "  !rm -rf ./wavs_tmp\n",
        "  !mkdir ./wavs_final/wavs\n",
        "  !mv ./wavs_final/*.wav ./wavs_final/wavs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCOdFn6KLKvC"
      },
      "source": [
        "# 4. WAV Files Validation (optional)\n",
        "\n",
        "In this section, you can validate the quality of your WAV files and see their durations. You can optionally choose to create a subset of all WAV files that conform to your minimum and maximum audio length preference (see the last step of this section)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2u9wKGIE2wb"
      },
      "outputs": [],
      "source": [
        "# download and compile the Waveform Amplitude Distribution Analysis tool (WADA)\n",
        "# used to analyze the Signal-to-Noise Ratio Estimation in your WAV files\n",
        "# ... nothing here is configurable, just run this cell and check the output if you like\n",
        "!wget http://www.cs.cmu.edu/~robust/archive/algorithms/WADA_SNR_IS_2008/WadaSNR.tar.gz\n",
        "!mkdir WADA_SNR_IS_2008/ && tar -xvf WadaSNR.tar.gz -C WADA_SNR_IS_2008\n",
        "!cd ./WADA_SNR_IS_2008/Build/ && rm -rf *.o && make clean && make\n",
        "\n",
        "import sys\n",
        "import glob\n",
        "import subprocess\n",
        "import tempfile\n",
        "import IPython\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from multiprocessing import Pool\n",
        "from matplotlib import pylab as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Set the meta parameters\n",
        "DATA_PATH = wavs_final_path + \"/wavs\"\n",
        "NUM_PROC = 1\n",
        "CURRENT_PATH = \"./\"\n",
        "\n",
        "# define the SNR compute function\n",
        "def compute_file_snr(file_path):\n",
        "    \"\"\" Convert given file to required format with FFMPEG and process with WADA.\"\"\"\n",
        "    _, sr = sf.read(file_path)\n",
        "    new_file = file_path.replace(\".wav\", \"_tmp.wav\")\n",
        "    print(new_file)\n",
        "    if sr != 16000:\n",
        "      command = f'ffmpeg -i \"{file_path}\" -ac 1 -acodec pcm_s16le -y -ar 16000 \"{new_file}\"'\n",
        "    else:\n",
        "      command = f'cp \"{file_path}\" \"{new_file}\"'\n",
        "    os.system(command)\n",
        "    output = !./WADA_SNR_IS_2008/Exe/WADASNR -i {new_file} -t ./WADA_SNR_IS_2008/Exe/Alpha0.400000.txt -ifmt mswav\n",
        "    snr = float(output[-2].split()[-2])\n",
        "    os.system(f'rm \"{new_file}\"')\n",
        "    return snr, file_path\n",
        "\n",
        "# define SNR results output function\n",
        "def output_snr_with_audio(idx):\n",
        "    file_idx = file_idxs[idx]\n",
        "    file_name = file_names[file_idx]\n",
        "    wav, sr = sf.read(file_name)\n",
        "    # multi channel to single channel\n",
        "    if len(wav.shape) == 2:\n",
        "        wav = wav[:, 0]\n",
        "    print(f\" > {file_name} - snr:{snrs[file_idx]}\")\n",
        "    IPython.display.display(IPython.display.Audio(wav, rate=sr))\n",
        "\n",
        "# run WADA script\n",
        "!./WADA_SNR_IS_2008/Exe/WADASNR -i ./WADA_SNR_IS_2008/SampleCorrupt/sb01_00dB_White.sph -t ./WADA_SNR_IS_2008/Exe/Alpha0.400000.txt -ifmt nist\n",
        "\n",
        "# validate number of WAV files\n",
        "wav_files = glob.glob(f\"{DATA_PATH}/*.wav\", recursive=True)\n",
        "print(f\"Number of wav files found {len(wav_files)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rsg_swEIFC1L"
      },
      "outputs": [],
      "source": [
        "# nothing to configure here either - just run and check the output if you want to\n",
        "if NUM_PROC == 1:\n",
        "    file_snrs = [None] * len(wav_files)\n",
        "    for idx, wav_file in tqdm(enumerate(wav_files)):\n",
        "        tup = compute_file_snr(wav_file)\n",
        "        file_snrs[idx] = tup\n",
        "else:\n",
        "    with Pool(NUM_PROC) as pool:\n",
        "        file_snrs = list(tqdm(pool.imap(compute_file_snr, wav_files), total=len(wav_files)))\n",
        "\n",
        "snrs = [tup[0] for tup in file_snrs]\n",
        "\n",
        "error_idxs = np.where(np.isnan(snrs) == True)[0]\n",
        "error_files = [wav_files[idx] for idx in error_idxs]\n",
        "\n",
        "file_snrs = [i for j, i in enumerate(file_snrs) if j not in error_idxs]\n",
        "file_names = [tup[1] for tup in file_snrs]\n",
        "snrs = [tup[0] for tup in file_snrs]\n",
        "file_idxs = np.argsort(snrs)\n",
        "\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(f\"Average SNR of the dataset:{np.mean(snrs)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTdeQqEaFIS_"
      },
      "outputs": [],
      "source": [
        "# find worse SNR files\n",
        "N = 3  # number of files to fetch\n",
        "for i in range(N):\n",
        "  #file_idx = file_idxs[i]\n",
        "  #print(file_names[file_idx] + '|' + str(snrs[file_idx]))\n",
        "  output_snr_with_audio(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nr8ods6KFJsW"
      },
      "outputs": [],
      "source": [
        "# find best recordings\n",
        "N = 3  # number of files to fetch\n",
        "for i in range(N):\n",
        "    output_snr_with_audio(-i-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cCSOvBrPFK-j"
      },
      "outputs": [],
      "source": [
        "# visualize SNRS\n",
        "plt.hist(snrs, bins=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "im4iuxMzFOVO"
      },
      "outputs": [],
      "source": [
        "# check durations of your WAV files to see if you can spot some that are too short\n",
        "# or too long ( i.e. < 1s or > 30s )\n",
        "#!echo \"filename|duration\" > wavdurations.csv;\n",
        "!echo \"\" > wavdurations.csv;\n",
        "\n",
        "!for file in ./wavs_final/wavs/*.wav; do duration=$(eval soxi -D \"$file\"); echo \"${file}|$duration\" >> wavdurations.csv; done\n",
        "\n",
        "!cat wavdurations.csv\n",
        "\n",
        "# @markdown ***WAV files duration check and filtering***\n",
        "# @markdown <br><small>WAV files should generally be longer than 1 second and shorter than about 10 - 12 seconds.</small>\n",
        "# @markdown <br><small>You can set your own limits and run this cell to see whether any of your WAV files are either too short or too long.</small>\n",
        "min_wav_duration_seconds = 1 # @param {type:\"number\"}\n",
        "max_wav_duration_seconds = 11 # @param {type:\"number\"}\n",
        "\n",
        "# @markdown <br><small>If you'd like to save only the files that conform to the min-max interval set above (along with updated labels.txt file) into a separate folder, tick this checkbox.</small>\n",
        "save_valid_files_separately = True # @param {type:\"boolean\"}\n",
        "\n",
        "files_too_short = {}\n",
        "files_too_long = {}\n",
        "min_seconds = 0\n",
        "max_seconds = 0\n",
        "some_files_filtered_out = False\n",
        "\n",
        "wavs_filtered_path = './wavs_filtered'\n",
        "\n",
        "if save_valid_files_separately == True:\n",
        "  !rm -rf $wavs_filtered_path\n",
        "  !mkdir $wavs_filtered_path && cd $wavs_filtered_path && mkdir wavs\n",
        "  !cp $wavs_final_path/training.csv $wavs_filtered_path\n",
        "  !cp $wavs_final_path/validation.csv $wavs_filtered_path\n",
        "\n",
        "  # load all lines of training and validation files,\n",
        "  # so we can remove the ones we don't want to see in them\n",
        "  with open( wavs_filtered_path + '/training.csv', 'r', newline = '', encoding='UTF8') as f:\n",
        "    lines_training = f.readlines()\n",
        "\n",
        "  with open( wavs_filtered_path + '/validation.csv', 'r', newline = '', encoding='UTF8') as f:\n",
        "    lines_validation = f.readlines()\n",
        "\n",
        "df = pd.read_csv('wavdurations.csv', sep='|', encoding='utf-8', usecols=[0, 1], names=['Filename', 'Duration'])\n",
        "for row in zip(df['Filename'].to_list(), df['Duration'].to_list()):\n",
        "  should_copy_this_file = True\n",
        "\n",
        "  if ( float( row[ 1 ] ) < min_wav_duration_seconds ):\n",
        "    files_too_short[ row[ 0 ] ] = row[ 1 ]\n",
        "    should_copy_this_file = False\n",
        "\n",
        "  if ( float( row[ 1 ] ) > max_wav_duration_seconds ):\n",
        "    files_too_long[ row[ 0 ] ] = row[ 1 ]\n",
        "    should_copy_this_file = False\n",
        "\n",
        "  if ( float( row[ 1 ] ) < min_seconds or min_seconds == 0 ):\n",
        "    min_seconds = float( row[ 1 ] )\n",
        "\n",
        "  if ( float( row[ 1 ] ) > max_seconds ):\n",
        "    max_seconds = float( row[ 1 ] )\n",
        "\n",
        "  filename_origin = row[ 0 ]\n",
        "\n",
        "  if save_valid_files_separately == True:\n",
        "    if should_copy_this_file:\n",
        "      # copy this file into the filtered files folder\n",
        "      filename_target = filename_origin.replace( wavs_final_path, wavs_filtered_path )\n",
        "      !cp $filename_origin $filename_target\n",
        "    else:\n",
        "      some_files_filtered_out = True\n",
        "      # remove this file from training and validation arrays\n",
        "      tmp_training = [];\n",
        "      tmp_validation = []\n",
        "      filename_clear = filename_origin.replace( wavs_final_path + '/wavs/', '' )\n",
        "      print( \"filtering out \" + filename_clear + \" (\" + str( row[ 1 ] ) + \"s)\" )\n",
        "\n",
        "      for line in lines_training:\n",
        "        if line.split('|')[0] != filename_clear:\n",
        "          tmp_training.append( line )\n",
        "\n",
        "      lines_training = tmp_training\n",
        "\n",
        "      for line in lines_validation:\n",
        "        if line.split('|')[0] != filename_clear:\n",
        "          tmp_validation.append( line )\n",
        "\n",
        "      lines_validation = tmp_validation\n",
        "\n",
        "# rewrite training and validation files, if we removed files from them\n",
        "if some_files_filtered_out == True:\n",
        "  with open( wavs_filtered_path + '/training.csv', 'w', newline = '', encoding='UTF8') as f:\n",
        "    for line in lines_training:\n",
        "      f.write( line )\n",
        "\n",
        "  with open( wavs_filtered_path + '/validation.csv', 'w', newline = '', encoding='UTF8') as f:\n",
        "    for line in lines_validation:\n",
        "      f.write( line )\n",
        "\n",
        "  print( \"WAVs length filtering successful, relevant files stored under \" + wavs_filtered_path )\n",
        "\n",
        "print( \"\\n\" )\n",
        "print(\"Minimum seconds in a WAV file found: \" + str( min_seconds ) )\n",
        "print(\"Maximum seconds in a WAV file found: \" + str( max_seconds ) )\n",
        "print( \"\\n\" )\n",
        "\n",
        "if ( len( files_too_short ) ):\n",
        "  print( \"WAV files too short:\" )\n",
        "  for file_path, file_duration in files_too_short.items():\n",
        "    print( \" - \" + file_path + \" = \" + str( file_duration ) + \"s\" )\n",
        "\n",
        "print( \"\\n\" )\n",
        "\n",
        "if ( len( files_too_long ) ):\n",
        "  print( \"WAV files too long:\" )\n",
        "  for file_path, file_duration in files_too_long.items():\n",
        "    print( \" - \" + file_path + \" = \" + str( file_duration ) + \"s\" )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEbROVxRTsXm"
      },
      "source": [
        "# 5. WAV Files Backup (optional)\n",
        "\n",
        "Here you can backup your processed WAV files and copy them onto Google Drive (if connected) or download a backup copy of the ZIP file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3h8gSutEHiC"
      },
      "outputs": [],
      "source": [
        "# @markdown ***Path for the WAVS backup ZIP file:***\n",
        "# @markdown <br><small>This is the relative path from your Drive root (e.g. *tts/wavs_processed.zip*)</small>\n",
        "# @markdown <br><small>Leave empty if you only want to zip-up your WAV files and download them manually.</small>\n",
        "wav_files_backup_path = \"tts/wavs_backup.zip\" # @param {type:\"string\"}\n",
        "make_backup_from = \"Filtered WAV files (result of running length check in Step 4)\" # @param [\"Unfiltered processed WAV files (Step 4 length check not ran)\", \"Filtered WAV files (result of running length check in Step 4)\"]\n",
        "\n",
        "# local WAV files backup file name\n",
        "wavs_backup_local_file_name = \"wavs_backup.zip\"\n",
        "\n",
        "# remove old file if we're backing up again\n",
        "!rm -f ./$wavs_backup_local_file_name\n",
        "\n",
        "# make backup of the resulting WAV files\n",
        "if make_backup_from == \"Unfiltered processed WAV files (Step 4 length check not ran)\":\n",
        "  !cd $wavs_final_path && zip -r ../$wavs_backup_local_file_name *\n",
        "else:\n",
        "  !cd $wavs_filtered_path && zip -r ../$wavs_backup_local_file_name *\n",
        "\n",
        "# copy backup onto Google Drive or print backup info\n",
        "if data_source == \"Google Drive (Google Colab only)\":\n",
        "  if wav_files_backup_path != \"\":\n",
        "    !rm -f /gdrive/MyDrive/$wav_files_backup_path\n",
        "    !cp ./$wavs_backup_local_file_name /gdrive/MyDrive/$wav_files_backup_path\n",
        "    print( \"\\n\\nThe backup file was successfully copied over to your Drive.\\nYou can also download the file \" + wavs_backup_local_file_name + \" directly from the root folder of this Notebook.\" )\n",
        "  else:\n",
        "    print( \"\\n\\nThe wav_files_backup_path setting was empty - the ZIP file was NOT copied over to your Drive.\\nYou can download the ZIP file (\" + wavs_backup_local_file_name + \") directly from the root folder of this Notebook.\" )\n",
        "else:\n",
        "  print( \"\\n\\nYour WAV files were backed up.\\nYou can download the ZIP file (\" + wavs_backup_local_file_name +\") directly from the root folder of this Notebook.\" )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-DA-R81AFNeY",
        "t843fpgS6jGO",
        "IEbROVxRTsXm"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}